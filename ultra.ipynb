{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 544x640 88.5ms\n",
      "Speed: 5.0ms preprocess, 88.5ms inference, 4.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "Meter reading: 20.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def draw_obb(image, obb):\n",
    "    # Draw the oriented bounding box on the image\n",
    "    if obb is not None:\n",
    "        for box in obb.xyxyxyxy.cpu().numpy():\n",
    "            box = box.reshape(4, 2).astype(int)\n",
    "            cv2.polylines(image, [box], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "    return image\n",
    "\n",
    "def get_center_point(box):\n",
    "    # Calculate center point of a bounding box\n",
    "    pts = box.reshape(4, 2)\n",
    "    center_x = np.mean(pts[:, 0])\n",
    "    center_y = np.mean(pts[:, 1])\n",
    "    return (center_x, center_y)\n",
    "\n",
    "def calculate_meter_reading(needle_corners, number_positions):\n",
    "    # Define standard number values for labeling from left to right\n",
    "    number_values = [0, 5, 10, 15, 20, 25, 30]\n",
    "    \n",
    "    # Sort number positions by x-coordinate (left to right)\n",
    "    sorted_positions = sorted(number_positions, key=lambda x: x[1][0])\n",
    "    \n",
    "    # Replace the detected values with our standardized values\n",
    "    labeled_positions = []\n",
    "    for i, (_, position) in enumerate(sorted_positions):\n",
    "        if i < len(number_values):\n",
    "            labeled_positions.append((number_values[i], position))\n",
    "    \n",
    "    # Calculate midpoint between corner 3 and corner 4 as the needle tip\n",
    "    needle_tip_x = (needle_corners[2][0] + needle_corners[3][0]) / 2\n",
    "    needle_tip_y = (needle_corners[2][1] + needle_corners[3][1]) / 2\n",
    "    needle_tip = np.array([needle_tip_x, needle_tip_y])\n",
    "    \n",
    "    # First check if needle is exactly at a number position\n",
    "    for value, position in labeled_positions:\n",
    "        distance = np.sqrt((needle_tip[0] - position[0])**2 + (needle_tip[1] - position[1])**2)\n",
    "        if distance < 15:  # Threshold for \"exact match\"\n",
    "            return value, \"exact_midpoint\"\n",
    "    \n",
    "    # If not exact, find the two numbers the needle is between\n",
    "    left_value = None\n",
    "    right_value = None\n",
    "    left_position = None\n",
    "    right_position = None\n",
    "    \n",
    "    for i in range(len(labeled_positions) - 1):\n",
    "        curr_value, curr_pos = labeled_positions[i]\n",
    "        next_value, next_pos = labeled_positions[i + 1]\n",
    "        \n",
    "        # Check if needle tip is between these two numbers (x-coordinate)\n",
    "        if curr_pos[0] <= needle_tip[0] <= next_pos[0]:\n",
    "            left_value = curr_value\n",
    "            right_value = next_value\n",
    "            left_position = curr_pos\n",
    "            right_position = next_pos\n",
    "            break\n",
    "    \n",
    "    # If needle is not between any two numbers, return the closest one\n",
    "    if left_value is None or right_value is None:\n",
    "        # Find the closest number\n",
    "        min_distance = float('inf')\n",
    "        closest_value = None\n",
    "        \n",
    "        for value, position in labeled_positions:\n",
    "            distance = np.sqrt((needle_tip[0] - position[0])**2 + (needle_tip[1] - position[1])**2)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_value = value\n",
    "        \n",
    "        return closest_value, \"closest_midpoint\"\n",
    "    \n",
    "    # Calculate interpolation based on x-coordinate position\n",
    "    total_x_distance = right_position[0] - left_position[0]\n",
    "    needle_x_distance = needle_tip[0] - left_position[0]\n",
    "    \n",
    "    # Calculate the ratio (0 to 1) of where the needle is between the two numbers\n",
    "    ratio = needle_x_distance / total_x_distance if total_x_distance > 0 else 0\n",
    "    \n",
    "    # Calculate the interpolated value with one decimal place precision\n",
    "    value_range = right_value - left_value\n",
    "    interpolated_value = left_value + (ratio * value_range)\n",
    "    \n",
    "    # Round to one decimal place\n",
    "    interpolated_value = round(interpolated_value, 1)\n",
    "    \n",
    "    return interpolated_value, \"interpolated_midpoint\"\n",
    "\n",
    "def main(analog_readingng, image_path):\n",
    "    # Load the YOLO OBB model for detection\n",
    "    model_3 = YOLO(analog_readingng)\n",
    "    \n",
    "    # Read the input image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not read image at\", image_path)\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Run inference using model_3 for detection\n",
    "    results = model_3(image)\n",
    "    \n",
    "    # Variables to store needle and number positions\n",
    "    needle_corners = None\n",
    "    number_positions = []\n",
    "    \n",
    "    # Iterate over the results and process detections\n",
    "    for r in results:\n",
    "        if r.obb is not None:\n",
    "            image = draw_obb(image, r.obb)\n",
    "            \n",
    "            boxes = r.obb.xyxyxyxy.cpu().numpy()\n",
    "            classes = r.obb.cls.cpu().numpy()\n",
    "            \n",
    "            for i, (box, class_id) in enumerate(zip(boxes, classes)):\n",
    "                class_name = r.names[int(class_id)]\n",
    "                center = get_center_point(box)\n",
    "                \n",
    "                # Draw the center point for all detections\n",
    "                cv2.circle(image, (int(center[0]), int(center[1])), 3, (0, 0, 255), -1)\n",
    "                \n",
    "                if class_name.lower() == \"needle\":\n",
    "                    # Store all corners of the needle\n",
    "                    needle_corners = box.reshape(4, 2)\n",
    "                  \n",
    "                elif class_name.isdigit() or class_name in [\"0\", \"5\", \"10\", \"15\", \"20\", \"25\", \"30\"] or class_name.lower() == \"numbers\":\n",
    "                    number_positions.append((0, center)) \n",
    "    \n",
    "    # Label the numbers from left to right for visualization\n",
    "    if number_positions:\n",
    "        number_values = [0, 5, 10, 15, 20, 25, 30]\n",
    "        sorted_positions = sorted(number_positions, key=lambda x: x[1][0])\n",
    "        \n",
    "        # Draw the labels on the image\n",
    "        for i, (_, position) in enumerate(sorted_positions):\n",
    "            if i < len(number_values):\n",
    "                label = str(number_values[i])\n",
    "                cv2.putText(image, label, \n",
    "                           (int(position[0]), int(position[1]) - 15),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    # Calculate the meter reading if we have needle and numbers\n",
    "    if needle_corners is not None and number_positions:\n",
    "        # Calculate midpoint between corner 3 and corner 4 for visualization\n",
    "        needle_tip_x = (needle_corners[2][0] + needle_corners[3][0]) / 2\n",
    "        needle_tip_y = (needle_corners[2][1] + needle_corners[3][1]) / 2\n",
    "        needle_tip = np.array([needle_tip_x, needle_tip_y])\n",
    "                \n",
    "        reading, method = calculate_meter_reading(needle_corners, number_positions)\n",
    "        if reading is not None:\n",
    "            result_text = f\"Meter reading: {reading}\"\n",
    "            print(result_text)\n",
    "            \n",
    "            # Visualize the connection between the used needle midpoint and closest number\n",
    "            sorted_positions = sorted(number_positions, key=lambda x: x[1][0])\n",
    "            labeled_positions = []\n",
    "            for i, (_, position) in enumerate(sorted_positions):\n",
    "                if i < len(number_values):\n",
    "                    labeled_positions.append((number_values[i], position))\n",
    "            \n",
    "            # Find the two values the needle is between (for interpolation visualization)\n",
    "            left_pos = None\n",
    "            right_pos = None\n",
    "            \n",
    "            for i in range(len(labeled_positions) - 1):\n",
    "                curr_value, curr_pos = labeled_positions[i]\n",
    "                next_value, next_pos = labeled_positions[i + 1]\n",
    "                \n",
    "                # Check if needle tip is between these two numbers (x-coordinate)\n",
    "                if curr_pos[0] <= needle_tip[0] <= next_pos[0]:\n",
    "                    left_pos = curr_pos\n",
    "                    right_pos = next_pos\n",
    "                    break\n",
    "            \n",
    "            # Draw visualization lines\n",
    "            if \"interpolated\" in method and left_pos is not None and right_pos is not None:\n",
    "                # Draw lines to both adjacent numbers\n",
    "                cv2.line(image, \n",
    "                         (int(needle_tip[0]), int(needle_tip[1])), \n",
    "                         (int(left_pos[0]), int(left_pos[1])), \n",
    "                         (255, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.line(image, \n",
    "                         (int(needle_tip[0]), int(needle_tip[1])), \n",
    "                         (int(right_pos[0]), int(right_pos[1])), \n",
    "                         (255, 0, 255), 1, cv2.LINE_AA)\n",
    "                \n",
    "                # Draw the interpolation region\n",
    "                pts = np.array([\n",
    "                    [int(left_pos[0]), int(left_pos[1])],\n",
    "                    [int(right_pos[0]), int(right_pos[1])],\n",
    "                    [int(needle_tip[0]), int(needle_tip[1])]\n",
    "                ], np.int32)\n",
    "               \n",
    "            else:\n",
    "                # Find the closest position for non-interpolated readings\n",
    "                closest_position = None\n",
    "                min_distance = float('inf')\n",
    "                \n",
    "                for _, position in labeled_positions:\n",
    "                    distance = np.sqrt((needle_tip[0] - position[0])**2 + \n",
    "                                     (needle_tip[1] - position[1])**2)\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        closest_position = position\n",
    "                \n",
    "                if closest_position is not None:\n",
    "                    # Draw a line connecting the needle midpoint and the closest number\n",
    "                    cv2.line(image, \n",
    "                            (int(needle_tip[0]), int(needle_tip[1])), \n",
    "                            (int(closest_position[0]), int(closest_position[1])), \n",
    "                            (255, 0, 255), 2)\n",
    "        else:\n",
    "            print(\"Needle position is out of range\")\n",
    "    else:\n",
    "        if needle_corners is None:\n",
    "            print(\"Needle not detected\")\n",
    "        if not number_positions:\n",
    "            print(\"No numbers detected\")\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    analog_readingng = \"Models/analog_reading_v2.pt\"\n",
    "    image_path = \"cropped_images/297.png\"\n",
    "    main(analog_readingng, image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anlog pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 69.0ms\n",
      "Speed: 5.0ms preprocess, 69.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x512 79.0ms\n",
      "Speed: 2.0ms preprocess, 79.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Meter reading: 20.3 (interpolated_midpoint)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# -----------------------------\n",
    "# Part 1: Helper functions for cropping\n",
    "# -----------------------------\n",
    "\n",
    "def draw_obb(image, obb):\n",
    "    \"\"\"Draw oriented bounding boxes on an image.\"\"\"\n",
    "    boxes = obb.xyxyxyxy.cpu().numpy()\n",
    "    for box in boxes:\n",
    "        pts = box.reshape(4, 2).astype(np.int32)\n",
    "        cv2.polylines(image, [pts], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "    return image\n",
    "\n",
    "def order_points(pts):\n",
    "    \"\"\"Order 4 points as top-left, top-right, bottom-right, bottom-left.\"\"\"\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def crop_region(image, obb):\n",
    "    \"\"\"\n",
    "    Crop the meter region from the image using the OBB.\n",
    "    Uses a perspective transformation based on the minimal area rectangle.\n",
    "    \"\"\"\n",
    "    boxes = obb.xyxyxyxy.cpu().numpy()\n",
    "    if len(boxes) == 0:\n",
    "        return None\n",
    "    # Use the first detected box for cropping.\n",
    "    box = boxes[0]\n",
    "    pts = box.reshape(4, 2).astype(np.float32)\n",
    "    \n",
    "    # Get the minimal area rectangle for the points.\n",
    "    rect = cv2.minAreaRect(pts)\n",
    "    width = int(rect[1][0])\n",
    "    height = int(rect[1][1])\n",
    "    if width <= 0 or height <= 0:\n",
    "        return None\n",
    "\n",
    "    # Destination points for the warp (top-left, top-right, bottom-right, bottom-left)\n",
    "    dst_pts = np.array([\n",
    "        [0, 0],\n",
    "        [width - 1, 0],\n",
    "        [width - 1, height - 1],\n",
    "        [0, height - 1]], dtype=np.float32)\n",
    "    \n",
    "    # Order the source points and compute the perspective transform.\n",
    "    ordered_pts = order_points(pts)\n",
    "    M = cv2.getPerspectiveTransform(ordered_pts, dst_pts)\n",
    "    cropped = cv2.warpPerspective(image, M, (width, height))\n",
    "    return cropped\n",
    "\n",
    "def detect_and_crop_region(analog_box_model, image_path):\n",
    "    \"\"\"\n",
    "    Detect the meter region using analog_box.pt and return the cropped image.\n",
    "    \"\"\"\n",
    "    model = YOLO(analog_box_model)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not read image at\", image_path)\n",
    "        sys.exit(1)\n",
    "    \n",
    "    results = model(image)\n",
    "    for r in results:\n",
    "        if hasattr(r, \"obb\") and r.obb is not None:\n",
    "            cropped = crop_region(image, r.obb)\n",
    "            if cropped is not None:\n",
    "                return cropped\n",
    "    print(\"No meter detected.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# -----------------------------\n",
    "# Part 2: Meter reading functions (provided calculation code)\n",
    "# -----------------------------\n",
    "\n",
    "def get_center_point(box):\n",
    "    \"\"\"Calculate the center point of a bounding box (4 corners).\"\"\"\n",
    "    pts = box.reshape(4, 2)\n",
    "    center_x = np.mean(pts[:, 0])\n",
    "    center_y = np.mean(pts[:, 1])\n",
    "    return (center_x, center_y)\n",
    "\n",
    "def calculate_meter_reading(needle_corners, number_positions):\n",
    "    \"\"\"\n",
    "    Given the needle corners and number positions, calculate the meter reading.\n",
    "    The numbers are standardized as [0, 5, 10, 15, 20, 25, 30].\n",
    "    \"\"\"\n",
    "    number_values = [0, 5, 10, 15, 20, 25, 30]\n",
    "    \n",
    "    # Sort number positions left-to-right by x-coordinate.\n",
    "    sorted_positions = sorted(number_positions, key=lambda x: x[1][0])\n",
    "    labeled_positions = []\n",
    "    for i, (_, position) in enumerate(sorted_positions):\n",
    "        if i < len(number_values):\n",
    "            labeled_positions.append((number_values[i], position))\n",
    "    \n",
    "    # Compute needle tip as midpoint between corner 3 and corner 4.\n",
    "    needle_tip_x = (needle_corners[2][0] + needle_corners[3][0]) / 2\n",
    "    needle_tip_y = (needle_corners[2][1] + needle_corners[3][1]) / 2\n",
    "    needle_tip = np.array([needle_tip_x, needle_tip_y])\n",
    "    \n",
    "    # Check if needle tip exactly matches a number position.\n",
    "    for value, position in labeled_positions:\n",
    "        distance = np.sqrt((needle_tip[0] - position[0])**2 + (needle_tip[1] - position[1])**2)\n",
    "        if distance < 15:  # threshold for \"exact match\"\n",
    "            return value, \"exact_midpoint\"\n",
    "    \n",
    "    # If not an exact match, find the two numbers between which the needle lies.\n",
    "    left_value = None\n",
    "    right_value = None\n",
    "    left_position = None\n",
    "    right_position = None\n",
    "    for i in range(len(labeled_positions) - 1):\n",
    "        curr_value, curr_pos = labeled_positions[i]\n",
    "        next_value, next_pos = labeled_positions[i + 1]\n",
    "        if curr_pos[0] <= needle_tip[0] <= next_pos[0]:\n",
    "            left_value = curr_value\n",
    "            right_value = next_value\n",
    "            left_position = curr_pos\n",
    "            right_position = next_pos\n",
    "            break\n",
    "\n",
    "    # If not between any two, return the closest.\n",
    "    if left_value is None or right_value is None:\n",
    "        min_distance = float('inf')\n",
    "        closest_value = None\n",
    "        for value, position in labeled_positions:\n",
    "            distance = np.sqrt((needle_tip[0] - position[0])**2 + (needle_tip[1] - position[1])**2)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_value = value\n",
    "        return closest_value, \"closest_midpoint\"\n",
    "    \n",
    "    # Interpolate based on x-distance.\n",
    "    total_x_distance = right_position[0] - left_position[0]\n",
    "    needle_x_distance = needle_tip[0] - left_position[0]\n",
    "    ratio = needle_x_distance / total_x_distance if total_x_distance > 0 else 0\n",
    "    value_range = right_value - left_value\n",
    "    interpolated_value = left_value + (ratio * value_range)\n",
    "    interpolated_value = round(interpolated_value, 1)\n",
    "    \n",
    "    return interpolated_value, \"interpolated_midpoint\"\n",
    "\n",
    "def process_meter_reading(analog_reading_model, image):\n",
    "    \"\"\"\n",
    "    Run detection on the provided (cropped) meter image using analog_reading_v2.pt,\n",
    "    compute the meter reading, and print the result.\n",
    "    \"\"\"\n",
    "    model = YOLO(analog_reading_model)\n",
    "    results = model(image)\n",
    "    \n",
    "    needle_corners = None\n",
    "    number_positions = []  # Each element is a tuple: (detected_label, center)\n",
    "    \n",
    "    # Process each detection result.\n",
    "    for r in results:\n",
    "        if hasattr(r, \"obb\") and r.obb is not None:\n",
    "            image = draw_obb(image, r.obb)\n",
    "            boxes = r.obb.xyxyxyxy.cpu().numpy()\n",
    "            classes = r.obb.cls.cpu().numpy()\n",
    "            \n",
    "            for box, class_id in zip(boxes, classes):\n",
    "                class_name = r.names[int(class_id)]\n",
    "                center = get_center_point(box)\n",
    "                cv2.circle(image, (int(center[0]), int(center[1])), 3, (0, 0, 255), -1)\n",
    "                \n",
    "                if class_name.lower() == \"needle\":\n",
    "                    needle_corners = box.reshape(4, 2)\n",
    "                # Check if class is a digit (or the word \"numbers\") representing meter numbers.\n",
    "                elif class_name.isdigit() or class_name in [\"0\", \"5\", \"10\", \"15\", \"20\", \"25\", \"30\"] or class_name.lower() == \"numbers\":\n",
    "                    number_positions.append((0, center))\n",
    "    \n",
    "    # Label the numbers (using standard ordering) on the image.\n",
    "    if number_positions:\n",
    "        number_values = [0, 5, 10, 15, 20, 25, 30]\n",
    "        sorted_positions = sorted(number_positions, key=lambda x: x[1][0])\n",
    "        for i, (_, position) in enumerate(sorted_positions):\n",
    "            if i < len(number_values):\n",
    "                label = str(number_values[i])\n",
    "                cv2.putText(image, label, \n",
    "                            (int(position[0]), int(position[1]) - 15),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    # Compute and print the meter reading if needle and numbers are detected.\n",
    "    if needle_corners is not None and number_positions:\n",
    "        needle_tip_x = (needle_corners[2][0] + needle_corners[3][0]) / 2\n",
    "        needle_tip_y = (needle_corners[2][1] + needle_corners[3][1]) / 2\n",
    "        needle_tip = np.array([needle_tip_x, needle_tip_y])\n",
    "                \n",
    "        reading, method = calculate_meter_reading(needle_corners, number_positions)\n",
    "        if reading is not None:\n",
    "            result_text = f\"Meter reading: {reading} ({method})\"\n",
    "            print(result_text)\n",
    "            \n",
    "            # Visualize connection between the needle tip and the nearest number.\n",
    "            number_values = [0, 5, 10, 15, 20, 25, 30]\n",
    "            sorted_positions = sorted(number_positions, key=lambda x: x[1][0])\n",
    "            labeled_positions = []\n",
    "            for i, (_, position) in enumerate(sorted_positions):\n",
    "                if i < len(number_values):\n",
    "                    labeled_positions.append((number_values[i], position))\n",
    "            \n",
    "            # Find adjacent numbers for interpolation visualization.\n",
    "            left_pos = None\n",
    "            right_pos = None\n",
    "            for i in range(len(labeled_positions) - 1):\n",
    "                curr_value, curr_pos = labeled_positions[i]\n",
    "                next_value, next_pos = labeled_positions[i + 1]\n",
    "                if curr_pos[0] <= needle_tip[0] <= next_pos[0]:\n",
    "                    left_pos = curr_pos\n",
    "                    right_pos = next_pos\n",
    "                    break\n",
    "            \n",
    "            if \"interpolated\" in method and left_pos is not None and right_pos is not None:\n",
    "                cv2.line(image, \n",
    "                         (int(needle_tip[0]), int(needle_tip[1])), \n",
    "                         (int(left_pos[0]), int(left_pos[1])), \n",
    "                         (255, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.line(image, \n",
    "                         (int(needle_tip[0]), int(needle_tip[1])), \n",
    "                         (int(right_pos[0]), int(right_pos[1])), \n",
    "                         (255, 0, 255), 1, cv2.LINE_AA)\n",
    "            else:\n",
    "                # Connect to closest number if not interpolated.\n",
    "                min_distance = float('inf')\n",
    "                closest_position = None\n",
    "                for _, position in labeled_positions:\n",
    "                    distance = np.sqrt((needle_tip[0] - position[0])**2 + \n",
    "                                       (needle_tip[1] - position[1])**2)\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        closest_position = position\n",
    "                if closest_position is not None:\n",
    "                    cv2.line(image, \n",
    "                             (int(needle_tip[0]), int(needle_tip[1])), \n",
    "                             (int(closest_position[0]), int(closest_position[1])), \n",
    "                             (255, 0, 255), 2)\n",
    "        else:\n",
    "            print(\"Needle position is out of range\")\n",
    "    else:\n",
    "        if needle_corners is None:\n",
    "            print(\"Needle not detected\")\n",
    "        if not number_positions:\n",
    "            print(\"No numbers detected\")\n",
    "            \n",
    "    return image\n",
    "\n",
    "# -----------------------------\n",
    "# Main Integration: Crop then process reading\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    # Paths for models and the input image.\n",
    "    analog_box_model = \"Models/analog_box_v2.pt\"           # Model to detect & crop meter region\n",
    "    analog_reading_model = \"Models/analog_reading_v2.pt\"  # Model to detect needle/numbers & calculate reading\n",
    "    full_image_path = \"extracted_frames/278.png\"         # Full input image\n",
    "    \n",
    "    # Step 1: Detect and crop the meter region.\n",
    "    cropped_meter = detect_and_crop_region(analog_box_model, full_image_path)\n",
    "    if cropped_meter is None:\n",
    "        print(\"Failed to crop the meter region.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    # Step 2: Process the cropped meter image to calculate and print the meter reading.\n",
    "    processed_image = process_meter_reading(analog_reading_model, cropped_meter)\n",
    "    cv2.imshow(\"Processed Meter\", processed_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. Load your Ultralytics model\n",
    "model = YOLO(\"Models/analog_box_v2.pt\").model  # get the underlying nn.Module\n",
    "\n",
    "# 2. Switch to eval + CPU\n",
    "model.eval().cpu()\n",
    "\n",
    "# 3. Create a dummy input matching your training size\n",
    "example = torch.zeros(1, 3, 640, 640)\n",
    "\n",
    "# 4. Trace or script\n",
    "traced = torch.jit.trace(model, example)        # for simple feed‑forward models\n",
    "# ─── or ─── \n",
    "# traced = torch.jit.script(model)              # if you need control‑flow support\n",
    "\n",
    "# 5. Save out a TorchScript file\n",
    "traced.save(\"Models/analog_box_v2_ts.pt\")\n",
    "# 6. Load the TorchScript model\n",
    "traced = torch.jit.load(\"Models/analog_box_v2_ts.pt\")\n",
    "# 7. Inference with TorchScript model\n",
    "traced(example)  # inference with TorchScript model\n",
    "# 8. Export to ONNX\n",
    "traced.save(\"Models/analog_box_v2.onnx\")\n",
    "# 9. Load the ONNX model\n",
    "import onnxruntime as ort\n",
    "ort_session = ort.InferenceSession(\"Models/analog_box_v2.onnx\")\n",
    "# 10. Inference with ONNX model\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: example.numpy()}\n",
    "ort_outs = ort_session.run(None, ort_inputs)  # inference with ONNX model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resistance N2N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_28.jpg: 11.7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define class map: label name -> integer index\n",
    "class_map = {\n",
    "    '0': 0, '1': 1, '2': 2, '3': 3, '4': 4,\n",
    "    '5': 5, '6': 6, '7': 7, '8': 8, '9': 9,\n",
    "    'C': 10, 'dot': 11\n",
    "}\n",
    "\n",
    "class TwoStageOCR:\n",
    "    def __init__(\n",
    "        self,\n",
    "        box_model_path: str,\n",
    "        digit_model_path: str,\n",
    "        cnn_model_path: str,\n",
    "        image_size: tuple = (128, 128),\n",
    "        conf_threshold: float = 0.25\n",
    "    ):\n",
    "        # Stage 1: panel detector (could be OBB or rectangular)\n",
    "        self.box_detector = YOLO(box_model_path)\n",
    "        # Stage 2: digit detector\n",
    "        self.digit_detector = YOLO(digit_model_path)\n",
    "        # CNN classifier for refined recognition\n",
    "        self.cnn = load_model(cnn_model_path)\n",
    "        # Inverted map: index -> label\n",
    "        self.inv_map = {v: k for k, v in class_map.items()}\n",
    "        self.image_size = image_size\n",
    "        self.conf_threshold = conf_threshold\n",
    "\n",
    "    def detect_panels(self, img: np.ndarray):\n",
    "        \"\"\"\n",
    "        Detect panels using either rectangular boxes or OBB, returning list of (crop, x_min).\n",
    "        \"\"\"\n",
    "        res = self.box_detector.predict(source=img, verbose=False)[0]\n",
    "        crops = []\n",
    "\n",
    "        # Try rectangular boxes\n",
    "        if hasattr(res, 'boxes') and res.boxes is not None:\n",
    "            boxes = res.boxes.xyxy.cpu().numpy()\n",
    "            confs = res.boxes.conf.cpu().numpy()\n",
    "        # Fallback to OBB\n",
    "        elif hasattr(res, 'obb') and res.obb is not None:\n",
    "            polys = res.obb.xyxyxyxy.cpu().numpy()\n",
    "            confs = res.obb.conf.cpu().numpy()\n",
    "            # Convert polygons to xyxy\n",
    "            boxes = []\n",
    "            for poly in polys:\n",
    "                pts = poly.reshape(4, 2).astype(int)\n",
    "                x1, y1 = pts.min(axis=0)\n",
    "                x2, y2 = pts.max(axis=0)\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "            boxes = np.array(boxes)\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        # Filter by confidence\n",
    "        for (x1, y1, x2, y2), conf in zip(boxes, confs):\n",
    "            if conf < self.conf_threshold:\n",
    "                continue\n",
    "            x1_i, y1_i, x2_i, y2_i = map(int, [x1, y1, x2, y2])\n",
    "            crop = img[y1_i:y2_i, x1_i:x2_i]\n",
    "            crops.append((crop, x1_i))\n",
    "        return crops\n",
    "\n",
    "    def ocr_array(self, crop: np.ndarray) -> str:\n",
    "        \"\"\"\n",
    "        Runs digit detection and CNN classification on a cropped panel.\n",
    "        Returns the recognized string.\n",
    "        \"\"\"\n",
    "        res2 = self.digit_detector.predict(source=crop, verbose=False)[0]\n",
    "        boxes2 = res2.boxes.xyxy.cpu().numpy()\n",
    "        confs2 = res2.boxes.conf.cpu().numpy()\n",
    "        mask2 = confs2 >= self.conf_threshold\n",
    "        if not mask2.any():\n",
    "            return \"\"\n",
    "\n",
    "        boxes2 = boxes2[mask2]\n",
    "        boxes2 = boxes2[np.argsort(boxes2[:, 0])]\n",
    "\n",
    "        digits = []\n",
    "        for x1, y1, x2, y2 in boxes2:\n",
    "            c = crop[int(y1):int(y2), int(x1):int(x2)]\n",
    "            gray = cv2.cvtColor(c, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(gray, self.image_size)\n",
    "            inp = resized.astype(\"float32\") / 255.0\n",
    "            inp = inp.reshape(1, self.image_size[0], self.image_size[1], 1)\n",
    "            probs = self.cnn.predict(inp, verbose=False)\n",
    "            idx = int(np.argmax(probs, axis=1)[0])\n",
    "            label = self.inv_map[idx]\n",
    "            digits.append('.' if label == 'dot' else label)\n",
    "        return \"\".join(digits)\n",
    "\n",
    "    def ocr_image(self, image_path: str) -> str:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Cannot read {image_path}\")\n",
    "        panels = self.detect_panels(img)\n",
    "        if not panels:\n",
    "            return \"\"\n",
    "        panels = sorted(panels, key=lambda x: x[1])\n",
    "        results = [self.ocr_array(crop) for crop, _ in panels]\n",
    "        return \" \".join([r for r in results if r])\n",
    "\n",
    "# -------------------\n",
    "# Main pipeline\n",
    "# -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    box_model = \"Models/res_temp_box.pt\"\n",
    "    digit_model = \"Models/res_detect.pt\"\n",
    "    cnn_model  = \"Models/digit_cnn_model_1.2.h5\"\n",
    "\n",
    "    ocr = TwoStageOCR(\n",
    "        box_model_path=box_model,\n",
    "        digit_model_path=digit_model,\n",
    "        cnn_model_path=cnn_model,\n",
    "        image_size=(128, 128),\n",
    "        conf_threshold=0.5\n",
    "    )\n",
    "\n",
    "    input_folder = \"test_images/cd_cr/resistance\"\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "        path = os.path.join(input_folder, fname)\n",
    "        text = ocr.ocr_image(path)\n",
    "        print(f\"{fname}: {text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature N2N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "\n",
    "# ----------------- Helper Functions -----------------\n",
    "\n",
    "def order_points(pts: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Orders 4 points in the order: top-left, top-right, bottom-right, bottom-left.\n",
    "    \"\"\"\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]  # top-left\n",
    "    rect[2] = pts[np.argmax(s)]  # bottom-right\n",
    "\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]  # top-right\n",
    "    rect[3] = pts[np.argmax(diff)]  # bottom-left\n",
    "\n",
    "    return rect\n",
    "\n",
    "\n",
    "def crop_regions(image: np.ndarray, res, conf_threshold: float=0.6) -> list:\n",
    "    \"\"\"\n",
    "    Crops and deskews regions based on OBB detection, returning (crop, x_min).\n",
    "    Uses perspective transform to rotate the region upright.\n",
    "    \"\"\"\n",
    "    regions = []\n",
    "    if hasattr(res, 'obb') and res.obb is not None:\n",
    "        polys = res.obb.xyxyxyxy.cpu().numpy()\n",
    "        confs = res.obb.conf.cpu().numpy()\n",
    "        for poly, conf in zip(polys, confs):\n",
    "            if conf < conf_threshold:\n",
    "                continue\n",
    "            pts = poly.reshape(4, 2).astype(np.float32)\n",
    "            # Order points and compute destination rectangle\n",
    "            rect = order_points(pts)\n",
    "            (tl, tr, br, bl) = rect\n",
    "            widthA = np.linalg.norm(br - bl)\n",
    "            widthB = np.linalg.norm(tr - tl)\n",
    "            maxW = int(max(widthA, widthB))\n",
    "\n",
    "            heightA = np.linalg.norm(tr - br)\n",
    "            heightB = np.linalg.norm(tl - bl)\n",
    "            maxH = int(max(heightA, heightB))\n",
    "\n",
    "            dst = np.array([\n",
    "                [0, 0],\n",
    "                [maxW - 1, 0],\n",
    "                [maxW - 1, maxH - 1],\n",
    "                [0, maxH - 1]\n",
    "            ], dtype=\"float32\")\n",
    "\n",
    "            # Perspective transform\n",
    "            M = cv2.getPerspectiveTransform(rect, dst)\n",
    "            warp = cv2.warpPerspective(image, M, (maxW, maxH))\n",
    "            x_min = int(rect[:, 0].min())\n",
    "            regions.append((warp, x_min))\n",
    "    return regions\n",
    "\n",
    "# ----------------- Main OCR Class -----------------\n",
    "class TwoStageOCR:\n",
    "    def __init__(\n",
    "        self,\n",
    "        box_model_path: str,\n",
    "        yolo_model_path: str,\n",
    "        cnn_model_path: str,\n",
    "        image_size=(28, 28),\n",
    "        conf_threshold=0.25\n",
    "    ):\n",
    "        # Stage 1: panel/region detector\n",
    "        self.box_detector = YOLO(box_model_path)\n",
    "        # Stage 2: digit detector for refined localization\n",
    "        self.digit_detector = YOLO(yolo_model_path)\n",
    "        # CNN for final classification\n",
    "        self.cnn = tf.keras.models.load_model(cnn_model_path, compile=False)\n",
    "\n",
    "        # Embedded class names for LeNet\n",
    "        class_names = ['0','1','2','3','4','5','6','7','8','9','C','dot']\n",
    "        self.inv_map = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.conf_threshold = conf_threshold\n",
    "\n",
    "    def preprocess_crop(self, crop: np.ndarray) -> np.ndarray:\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, self.image_size)\n",
    "        normed = resized.astype(np.float32) / 255.0\n",
    "        return normed.reshape(1, *self.image_size, 1)\n",
    "\n",
    "    def ocr_panel(self, panel: np.ndarray) -> str:\n",
    "        \"\"\"\n",
    "        Detect digits in a cropped panel and classify using CNN.\n",
    "        \"\"\"\n",
    "        res = self.digit_detector.predict(source=panel, verbose=False)[0]\n",
    "        boxes = res.boxes.xyxy.cpu().numpy()\n",
    "        confs = res.boxes.conf.cpu().numpy()\n",
    "        # Filter by confidence\n",
    "        mask = confs >= self.conf_threshold\n",
    "        boxes = boxes[mask]\n",
    "        if boxes.size == 0:\n",
    "            return \"\"\n",
    "        # Sort left-to-right\n",
    "        boxes = boxes[np.argsort(boxes[:, 0])]\n",
    "\n",
    "        digits = []\n",
    "        for x1, y1, x2, y2 in boxes:\n",
    "            c = panel[int(y1):int(y2), int(x1):int(x2)]\n",
    "            inp = self.preprocess_crop(c)\n",
    "            probs = self.cnn.predict(inp, verbose=False)\n",
    "            idx = int(np.argmax(probs, axis=1)[0])\n",
    "            label = self.inv_map[idx]\n",
    "            digits.append(label)\n",
    "        return ''.join(digits)\n",
    "\n",
    "    def ocr_image(self, image_path: str) -> str:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Cannot read {image_path}\")\n",
    "\n",
    "        # Stage 1: detect and crop panels\n",
    "        res_panels = self.box_detector.predict(source=img, verbose=False)[0]\n",
    "        panels = crop_regions(img, res_panels)\n",
    "        if not panels:\n",
    "            return \"\"\n",
    "        # Sort panels by x-coordinate\n",
    "        panels = sorted(panels, key=lambda x: x[1])\n",
    "\n",
    "        # Stage 2: OCR each panel\n",
    "        results = []\n",
    "        for panel_crop, _ in panels:\n",
    "            text = self.ocr_panel(panel_crop)\n",
    "            if text:\n",
    "                results.append(text)\n",
    "        return ' '.join(results)\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Example pipeline\n",
    "# -------------------\n",
    "if __name__ == '__main__':\n",
    "    box_model = 'Models/res_temp_box.pt'\n",
    "    yolo_model = 'Models/temp_detection.pt'\n",
    "    cnn_model  = 'Models/lenet7seg.h5'\n",
    "\n",
    "    ocr = TwoStageOCR(\n",
    "        box_model_path=box_model,\n",
    "        yolo_model_path=yolo_model,\n",
    "        cnn_model_path=cnn_model,\n",
    "        image_size=(28,28),\n",
    "        conf_threshold=0.3\n",
    "    )\n",
    "\n",
    "    input_dir = 'test_images/cd_cr/temp'\n",
    "    for fname in os.listdir(input_dir):\n",
    "        if not fname.lower().endswith(('.png','.jpg','.jpeg')):\n",
    "            continue\n",
    "        full = os.path.join(input_dir, fname)\n",
    "        print(f\"{fname} -> {ocr.ocr_image(full)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xsen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
